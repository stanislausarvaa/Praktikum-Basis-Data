{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "115f65d3",
      "metadata": {
        "id": "115f65d3"
      },
      "source": [
        "# Hands-On Pertemuan 9: Spark SQL"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f0fa7f9",
      "metadata": {
        "id": "7f0fa7f9"
      },
      "source": [
        "## Tujuan:\n",
        "- Mengasah keterampilan analisis data menggunakan Spark SQL.\n",
        "- Melakukan lebih banyak latihan SQL yang mengarah ke skenario dunia nyata.\n",
        "- Mempersiapkan mahasiswa untuk menggunakan Spark SQL dalam proyek besar.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a45dcb9",
      "metadata": {
        "id": "3a45dcb9"
      },
      "source": [
        "### 1. Refresher: Basic SQL Operations in Spark SQL\n",
        "- **Tugas 1**: Ulangi pemahaman Anda tentang SQL dasar dengan menjalankan queries sederhana pada dataset di Spark SQL.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "qembvfanQwH2",
        "outputId": "3a103f11-1185-4d15-ccd7-fecd7e3fd252",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "qembvfanQwH2",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "974a023b",
      "metadata": {
        "id": "974a023b",
        "outputId": "990a10a9-8166-43ca-f4c0-ac80edbdd791",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+------+------+------+\n",
            "| Name|Age|Gender|Salary|DeptId|\n",
            "+-----+---+------+------+------+\n",
            "|James| 34|     M|  3000|     1|\n",
            "| Anna| 28|     F|  4100|     2|\n",
            "|  Lee| 23|     M|  2700|     1|\n",
            "+-----+---+------+------+------+\n",
            "\n",
            "+----+---+\n",
            "|Name|Age|\n",
            "+----+---+\n",
            "|Anna| 28|\n",
            "+----+---+\n",
            "\n",
            "+------------------+\n",
            "|       avg(Salary)|\n",
            "+------------------+\n",
            "|3266.6666666666665|\n",
            "+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"Praktikum Big Data\").getOrCreate()\n",
        "\n",
        "data = [\n",
        "    ('James', 34, 'M', 3000, 1),\n",
        "    ('Anna', 28, 'F', 4100, 2),\n",
        "    ('Lee', 23, 'M', 2700, 1)\n",
        "]\n",
        "columns = ['Name', 'Age', 'Gender', 'Salary', 'DeptId']\n",
        "df = spark.createDataFrame(data, schema=columns)\n",
        "df.createOrReplaceTempView('employees')\n",
        "spark.sql('SELECT * FROM employees').show()\n",
        "spark.sql('SELECT Name, Age FROM employees WHERE Salary > 3000').show()\n",
        "spark.sql('SELECT AVG(Salary) FROM employees').show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fd8b4f1",
      "metadata": {
        "id": "9fd8b4f1"
      },
      "source": [
        "### 2. Advanced Queries for Data Analysis\n",
        "Gunakan queries lebih kompleks, melibatkan grouping, filtering, dan subqueries.\n",
        "- **Tugas 2**: Buat SQL query yang menghitung total gaji berdasarkan jenis kelamin dan usia.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4fc8a9e6",
      "metadata": {
        "id": "4fc8a9e6",
        "outputId": "a4afe255-5378-4407-ac6d-bb2ed6a555c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------+---+\n",
            "|Gender|TotalSalary|Age|\n",
            "+------+-----------+---+\n",
            "|     M|       2700| 23|\n",
            "|     F|       4100| 28|\n",
            "|     M|       3000| 34|\n",
            "+------+-----------+---+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql('''\n",
        "SELECT Gender, SUM(Salary) as TotalSalary, Age\n",
        "FROM employees\n",
        "GROUP BY Gender, Age\n",
        "ORDER BY Age\n",
        "\n",
        "''').show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18b3ccb1",
      "metadata": {
        "id": "18b3ccb1"
      },
      "source": [
        "- **Tugas Tambahan 2**:\n",
        "1. Cari rata-rata gaji per departemen.\n",
        "2. Temukan karyawan yang memiliki gaji di atas rata-rata untuk gender masing-masing.\n",
        "3. Buat ranking karyawan berdasarkan gaji dalam departemen mereka.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"SELECT DeptId, AVG(Salary) AS AvgSalary FROM employees GROUP BY DeptId\").show()"
      ],
      "metadata": {
        "id": "ZOE3A4cQUz10",
        "outputId": "94fe7805-4b10-4197-91c1-8a841ceb46fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ZOE3A4cQUz10",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---------+\n",
            "|DeptId|AvgSalary|\n",
            "+------+---------+\n",
            "|     1|   2850.0|\n",
            "|     2|   4100.0|\n",
            "+------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "    SELECT e.*\n",
        "    FROM employees e\n",
        "    JOIN (\n",
        "        SELECT Gender, AVG(Salary) AS AvgSalaryPerGender\n",
        "        FROM employees\n",
        "        GROUP BY Gender\n",
        "    ) g ON e.Gender = g.Gender\n",
        "    WHERE e.Salary > g.AvgSalaryPerGender\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "id": "D5tSxi4YU0Fy",
        "outputId": "9792a9c1-e647-4100-bb22-5e671280d474",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "D5tSxi4YU0Fy",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+------+------+------+\n",
            "| Name|Age|Gender|Salary|DeptId|\n",
            "+-----+---+------+------+------+\n",
            "|James| 34|     M|  3000|     1|\n",
            "+-----+---+------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "    SELECT *, RANK() OVER (PARTITION BY DeptId ORDER BY Salary DESC) AS SalaryRank\n",
        "    FROM employees\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "id": "S9JImsdmU0L8",
        "outputId": "c9bc707f-10d0-415d-d36d-39ec277d6a76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "S9JImsdmU0L8",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+------+------+------+----------+\n",
            "| Name|Age|Gender|Salary|DeptId|SalaryRank|\n",
            "+-----+---+------+------+------+----------+\n",
            "|James| 34|     M|  3000|     1|         1|\n",
            "|  Lee| 23|     M|  2700|     1|         2|\n",
            "| Anna| 28|     F|  4100|     2|         1|\n",
            "+-----+---+------+------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c4fffdc",
      "metadata": {
        "id": "3c4fffdc"
      },
      "source": [
        "### 3. Penggunaan Window Functions dan Subqueries\n",
        "Latihan penggunaan window functions untuk menemukan karyawan dengan gaji tertinggi dan urutannya berdasarkan kelompok usia.\n",
        "- **Tugas 3**: Terapkan window functions untuk menemukan top 3 karyawan dalam kelompok usia tertentu.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb927310",
      "metadata": {
        "id": "eb927310",
        "outputId": "50770450-bef5-4eb2-8dcb-3ca01a1e3afc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+------+----+\n",
            "| Name|Age|Salary|rank|\n",
            "+-----+---+------+----+\n",
            "|  Lee| 23|  2700|   1|\n",
            "| Anna| 28|  4100|   1|\n",
            "|James| 34|  3000|   1|\n",
            "+-----+---+------+----+\n",
            "\n",
            "+-----+---+------+\n",
            "| Name|Age|Salary|\n",
            "+-----+---+------+\n",
            "|  Lee| 23|  2700|\n",
            "| Anna| 28|  4100|\n",
            "|James| 34|  3000|\n",
            "+-----+---+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql('''\n",
        "SELECT Name, Age, Salary, ROW_NUMBER() OVER (PARTITION BY Age ORDER BY Salary DESC) as rank\n",
        "FROM employees\n",
        "''').show()\n",
        "spark.sql('''\n",
        "SELECT Name, Age, Salary\n",
        "FROM (\n",
        "    SELECT Name, Age, Salary, ROW_NUMBER() OVER (PARTITION BY Age ORDER BY Salary DESC) as rank\n",
        "    FROM employees\n",
        ")\n",
        "WHERE rank <= 3\n",
        "''').show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fb43ac4",
      "metadata": {
        "id": "5fb43ac4"
      },
      "source": [
        "### 4. Advanced Spark SQL Queries\n",
        "Menjelajahi queries yang lebih kompleks yang melibatkan multiple joins, subqueries, dan window functions.\n",
        "- **Tugas 4**: Demonstrasi penggunaan multi-level joins dan subqueries untuk analisis data yang mendalam.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1bfd9fd",
      "metadata": {
        "id": "f1bfd9fd"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('Pertemuan9').getOrCreate()\n",
        "\n",
        "# Data setup for complex SQL queries\n",
        "employees = spark.createDataFrame([\n",
        "    ('James', 34, 'M', 3000, 1),\n",
        "    ('Anna', 28, 'F', 4100, 2),\n",
        "    ('Lee', 23, 'M', 2700, 1)\n",
        "], ['Name', 'Age', 'Gender', 'Salary', 'DeptId'])\n",
        "departments = spark.createDataFrame([\n",
        "    (1, 'HR'),\n",
        "    (2, 'Marketing')\n",
        "], ['DeptId', 'DeptName'])\n",
        "projects = spark.createDataFrame([\n",
        "    (1, 'Project A'),\n",
        "    (2, 'Project B')\n",
        "], ['DeptId', 'ProjectName'])\n",
        "employees.createOrReplaceTempView('employees')\n",
        "departments.createOrReplaceTempView('departments')\n",
        "projects.createOrReplaceTempView('projects')\n",
        "\n",
        "# Complex SQL query involving multiple joins and subqueries\n",
        "spark.sql('''\n",
        "SELECT e.Name, e.Age, d.DeptName, p.ProjectName\n",
        "FROM employees e\n",
        "JOIN departments d ON e.DeptId = d.DeptId\n",
        "JOIN projects p ON e.DeptId = p.DeptId\n",
        "''').show()\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "SELECT\n",
        "    e.Name,\n",
        "    e.DeptId,\n",
        "    e.Salary,\n",
        "    AVG(e.Salary) OVER (PARTITION BY e.DeptId) AS AvgSalary,\n",
        "    RANK() OVER (PARTITION BY e.DeptId ORDER BY e.Salary DESC) AS SalaryRank\n",
        "FROM employees e\n",
        "JOIN departments d ON e.DeptId = d.DeptId\n",
        "\"\"\")\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "SELECT\n",
        "    e.Name,\n",
        "    e.Age,\n",
        "    e.Salary,\n",
        "    LEAD(e.Salary, 1) OVER (PARTITION BY e.DeptId ORDER BY e.Age) AS NextSalary,\n",
        "    e.Salary - LEAD(e.Salary, 1) OVER (PARTITION BY e.DeptId ORDER BY e.Age) AS SalaryDiff\n",
        "FROM employees e\n",
        "JOIN departments d ON e.DeptId = d.DeptId\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad25f1f0",
      "metadata": {
        "id": "ad25f1f0"
      },
      "source": [
        "Latihan mandiri untuk memperkuat pemahaman tentang Spark SQL dalam analisis data terdistribusi.\n",
        "- **Tugas 5**: Tuliskan query SQL untuk menemukan rata-rata gaji per departemen dan rangking setiap karyawan dalam departemen berdasarkan gaji.\n",
        "- **Tugas 6**: Gunakan window functions untuk menentukan tren gaji berdasarkan usia di setiap departemen.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88a2c206",
      "metadata": {
        "id": "88a2c206"
      },
      "source": [
        "### 5. Advanced Data Analysis and Visualization\n",
        "Penerapan teknik analisis data yang lebih canggih dan visualisasi menggunakan PySpark dan matplotlib.\n",
        "- **Tugas 7**: Lakukan analisis tren gaji menggunakan Spark SQL dan visualisasikan hasilnya.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a170f256",
      "metadata": {
        "id": "a170f256"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Advanced data analysis with visualization\n",
        "salary_trends = spark.sql('''\n",
        "SELECT Age, AVG(Salary) AS AverageSalary\n",
        "FROM employees\n",
        "GROUP BY Age\n",
        "ORDER BY Age\n",
        "''').toPandas()\n",
        "\n",
        "# Visualization of salary trends\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(salary_trends['Age'], salary_trends['AverageSalary'], marker='o')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Average Salary')\n",
        "plt.title('Salary Trends by Age')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd314ae9",
      "metadata": {
        "id": "dd314ae9"
      },
      "source": [
        "### 6. Homework\n",
        "- **Tugas 1**: Gunakan Spark SQL untuk mencari total gaji dan jumlah karyawan per departemen. Buat visualisasi perbandingan antar departemen.\n",
        "- **Tugas 2**: Temukan karyawan dengan gaji di atas rata-rata dalam setiap kelompok usia dan visualisasikan data ini dalam bentuk grafik batang atau pie chart.\n",
        "- **Tugas 3**: Buat dataset yang lebih besar (misalnya, 100+ baris) dan lakukan analisis mendalam menggunakan SQL functions seperti `SUM()`, `AVG()`, `COUNT()`, serta `JOIN` antar tabel serta buat visualisasi yang menarik.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "# Asumsikan Anda sudah memiliki SparkSession yang dinamakan 'spark' dan DataFrame 'employees', 'departments', dan 'projects'\n",
        "\n",
        "# 1. Total gaji dan jumlah karyawan per departemen\n",
        "total_salary_per_dept = spark.sql(\"\"\"\n",
        "SELECT\n",
        "    DeptId,\n",
        "    SUM(Salary) as TotalSalary,\n",
        "    COUNT(*) as NumEmployees\n",
        "FROM employees\n",
        "GROUP BY DeptId\n",
        "\"\"\")\n",
        "\n",
        "# 2. Karyawan dengan gaji di atas rata-rata per kelompok usia\n",
        "above_avg_salary = spark.sql(\"\"\"\n",
        "SELECT\n",
        "    Age,\n",
        "    COUNT(*) as NumEmployeesAboveAvg\n",
        "FROM employees\n",
        "GROUP BY Age\n",
        "HAVING AVG(Salary) < Salary\n",
        "\"\"\")\n",
        "\n",
        "# 3. Rata-rata gaji per proyek dan departemen\n",
        "avg_salary_per_project = spark.sql(\"\"\"\n",
        "SELECT\n",
        "    p.ProjectName,\n",
        "    d.DeptName,\n",
        "    AVG(e.Salary) as AvgSalary\n",
        "FROM employees e\n",
        "JOIN departments d ON e.DeptId = d.DeptId\n",
        "JOIN projects p ON e.DeptId = p.DeptId\n",
        "GROUP BY p.ProjectName, d.DeptName\n",
        "\"\"\")\n",
        "\n",
        "# Konversi ke Pandas DataFrame untuk visualisasi\n",
        "salary_df = total_salary_per_dept.toPandas()\n",
        "above_avg_salary_df = above_avg_salary.toPandas()\n",
        "avg_salary_df = avg_salary_per_project.toPandas()\n",
        "\n",
        "# Visualisasi\n",
        "# a. Total gaji dan jumlah karyawan per departemen\n",
        "plt.figure(figsize=(10, 6))\n",
        "salary_df.plot(x='DeptId', y=['TotalSalary', 'NumEmployees'], kind='bar')\n",
        "plt.title('Total Gaji dan Jumlah Karyawan per Departemen')\n",
        "plt.xlabel('Departemen')\n",
        "plt.ylabel('Jumlah')\n",
        "\n",
        "# b. Karyawan dengan gaji di atas rata-rata per kelompok usia\n",
        "plt.figure(figsize=(10, 6))\n",
        "above_avg_salary_df.plot(kind='bar', x='Age', y='NumEmployeesAboveAvg')\n",
        "plt.title('Jumlah Karyawan dengan Gaji di Atas Rata-Rata per Usia')\n",
        "plt.xlabel('Usia')\n",
        "plt.ylabel('Jumlah Karyawan')\n",
        "\n",
        "# c. Rata-rata gaji per proyek dan departemen (heatmap)\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(avg_salary_df.pivot('DeptName', 'ProjectName', 'AvgSalary'), annot=True, fmt=\".2f\")\n",
        "plt.title('Rata-rata Gaji per Proyek dan Departemen')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "yhP6fWCZmds4",
        "outputId": "505ff75c-e168-464c-f6a1-b3bddfc674cf"
      },
      "id": "yhP6fWCZmds4",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'spark' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c161e30f182e>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# 1. Total gaji dan jumlah karyawan per departemen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m total_salary_per_dept = spark.sql(\"\"\"\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mSELECT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mDeptId\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LM2w9-Wqmeen"
      },
      "id": "LM2w9-Wqmeen",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}